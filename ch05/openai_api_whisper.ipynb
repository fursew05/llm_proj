{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e368c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPEN_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc8923f",
   "metadata": {},
   "source": [
    "### STT (Speech To Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c73b0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'다시 말해봐 일단 내가 2천원 먼저 보내줄테니까 12,000원 나중에 보내줄게 왜 또 줄어? 가격이? 그만 그렇게 말하는거지 너 왔다며 아니 그냥 10,000원 보내주고 5,000원 나중에 대 12,000원 2,000원 하자 12,000원 2,000원 아니 1,000원은 뭐 그렇게 아쉬워 야 그럼 12,000원 12,000원 그냥 12,000원 두고 3,000원 그냥 아쉬워 나는 지금 많이 희생했잖아 나는 3,000원 내 버스비긴 해 내 교통비라서 미치겠네 아쉬워라 3,000원이 그걸 나중에 내면 된다니까 지금 내라는게 아니냐 몇번을 말해 언제 내가 보려면 계속 두사람 기다려야되는데 그건 니가 그냥 일을 안하는거네 돈없다고 찡찡대면서 돈은 아니잖아 일단 머리 자르고 돈은 보내주던 연락을 할게 있는 돈부터 계산을 해봐야 될거 아니야 막냉이 얼마인지 계산 안될 수 있잖아 일단 뭐 뭐가 됐든 일단 이따 말해 그래 업보가 되겠네 엥? 업보는 아니고'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"C://Users//fursew//project//open_ai//ch05//음성녹음.mp3\"\n",
    "\n",
    "with open(file_path,\"rb\") as f:\n",
    "    response = client.audio.transcriptions.create(\n",
    "        file=f,\n",
    "        model=\"whisper-1\",\n",
    "    )\n",
    "\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dad812b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'll cut my hair. Say that again. I'll send you 2,000 won first. I'll send you 12,000 won later. Why is the price going down? Stop talking like that. You said you were here. No, I'll just send you 10,000 won. I'll pay you 5,000 won later. Let's do 12,000 won, 2,000 won. 12,000 won, 2,000 won. 1,000 won is not enough. Then 12,000 won. You're not gonna give me 3,000 won? No, I've sacrificed a lot right now. I'll pay you 3,000 won later. It's my bus fare. It's my transportation fee. I'm sorry. I'll pay you 3,000 won later. I'll pay you 3,000 won later. I'm not asking you to pay me now. How many times do I have to tell you? When? I have to wait two more months to see you. You're just not working. You're complaining that you don't have money. I don't have money. I'll cut my hair first. I'll send you the money. I'll call you later. You have to pay me first. I don't know how much you have. I can't pay you. Whatever it is, I'll tell you later. Yeah, I'll give you a kiss. What?\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# translation을 통한 영어 번역\n",
    "with open(file_path,\"rb\") as f:\n",
    "    response = client.audio.translations.create(\n",
    "    file = f,\n",
    "    model = \"whisper-1\"\n",
    ")\n",
    "\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a480b20c",
   "metadata": {},
   "source": [
    "### 로컬에서 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "519994fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Using `chunk_length_s` is very experimental with seq2seq models. The results will not necessarily be entirely accurate and will have caveats. More information: https://github.com/huggingface/transformers/pull/20104. Ignore this warning with pipeline(..., ignore_warning=True). To use Whisper for long-form transcription, use rather the model's `generate` method directly as the model relies on it's own chunking mechanism (cf. Whisper original paper, section 3.8. Long-form Transcription).\n",
      "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
      "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' 다시 말해봐 일단 내가 이천원 먼저 보내줄테니깐 1만 2천원 나중에 보내줄게 왜 또 줄어 가격이 그만 그렇게 말하면 하지 너 왔다며 아니 그냥 만원 보내주고 오천원 나중에 돼 12,000원 12,000원 12,000원 아니 천 원이 하자 12,000원에 2,000원 아니 천원이 뭐 그 자조 저건 많이 터러 12,000원은 그냥 12,000원에 3해 너도 삼촌은 그게 아쉬워? 아니 나는 지금 많이 희생했잖아 나는 3천은 내 버스비긴 해가지고 내 교통비라서 아쉬워놔 3천원이 그걸 나중에 내면 된다니까 지금 내라는 게 아니냐 몇 번을 말해? 언제? 한 보려면 계속 두 달은 기다려야 되는데 그건 니가 그냥 일을 안 하는 거네 돈 없다고 찡찡대면서 일단 머리 자르고 돈을 보내주던 연락을 할게 있는 돈부터 계산을 해봐야 될 거 아니야 남는 돈이 얼마인지 계산 안될 수 있잖아 일단 뭐 뭐가 됐든 이따 말해 그래, 오뽀가 되겠네 엇? 엇보는 아니고', 'chunks': [{'timestamp': (0.0, 2.0), 'text': ' 다시 말해봐'}, {'timestamp': (2.0, 5.0), 'text': ' 일단 내가 이천원 먼저 보내줄테니깐'}, {'timestamp': (5.0, 9.08), 'text': ' 1만 2천원 나중에 보내줄게 왜 또 줄어 가격이'}, {'timestamp': (9.08, 10.54), 'text': ' 그만 그렇게 말하면 하지'}, {'timestamp': (10.54, 11.66), 'text': ' 너 왔다며'}, {'timestamp': (11.66, 14.0), 'text': ' 아니 그냥 만원 보내주고'}, {'timestamp': (14.0, 17.7), 'text': ' 오천원 나중에 돼 12,000원'}, {'timestamp': (17.7, 18.02), 'text': ' 12,000원'}, {'timestamp': (18.02, 18.72), 'text': ' 12,000원'}, {'timestamp': (18.72, 19.3), 'text': ' 아니 천 원이 하자 12,000원에 2,000원'}, {'timestamp': (19.3, 27.0), 'text': ' 아니 천원이 뭐 그 자조 저건 많이 터러 12,000원은 그냥 12,000원에 3해 너도 삼촌은 그게 아쉬워?'}, {'timestamp': (27.0, 30.0), 'text': ' 아니 나는 지금 많이 희생했잖아'}, {'timestamp': (30.0, 41.0), 'text': ' 나는 3천은 내 버스비긴 해가지고 내 교통비라서 아쉬워놔 3천원이 그걸 나중에 내면 된다니까'}, {'timestamp': (41.0, 44.0), 'text': ' 지금 내라는 게 아니냐 몇 번을 말해?'}, {'timestamp': (44.0, 49.48), 'text': ' 언제? 한 보려면 계속 두 달은 기다려야 되는데'}, {'timestamp': (49.48, 60.0), 'text': ' 그건 니가 그냥 일을 안 하는 거네 돈 없다고 찡찡대면서 일단 머리 자르고 돈을 보내주던 연락을 할게'}, {'timestamp': (60.0, 62.5), 'text': ' 있는 돈부터 계산을 해봐야 될 거 아니야'}, {'timestamp': (62.5, 71.0), 'text': ' 남는 돈이 얼마인지 계산 안될 수 있잖아 일단 뭐 뭐가 됐든 이따 말해'}, {'timestamp': (71.0, 73.34), 'text': ' 그래, 오뽀가 되겠네'}, {'timestamp': (73.34, 74.84), 'text': ' 엇? 엇보는 아니고'}]}\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"PATH\"] += os.pathsep + \"C://PMPG//ffmpeg-2025-07-23-git-829680f96a-full_build//bin\"\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    return_timestamps=True,\n",
    "    chunk_length_s=5,\n",
    "    stride_length_s=1,\n",
    ")\n",
    "\n",
    "sample = \"C://Users//fursew//project//open_ai//ch05//음성녹음.mp3\"\n",
    "\n",
    "result = pipe(sample)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57bedd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>다시 말해봐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>일단 내가 이천원 먼저 보내줄테니깐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.00</td>\n",
       "      <td>9.08</td>\n",
       "      <td>1만 2천원 나중에 보내줄게 왜 또 줄어 가격이</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.08</td>\n",
       "      <td>10.54</td>\n",
       "      <td>그만 그렇게 말하면 하지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.54</td>\n",
       "      <td>11.66</td>\n",
       "      <td>너 왔다며</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.66</td>\n",
       "      <td>14.00</td>\n",
       "      <td>아니 그냥 만원 보내주고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.00</td>\n",
       "      <td>17.70</td>\n",
       "      <td>오천원 나중에 돼 12,000원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17.70</td>\n",
       "      <td>18.02</td>\n",
       "      <td>12,000원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18.02</td>\n",
       "      <td>18.72</td>\n",
       "      <td>12,000원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.72</td>\n",
       "      <td>19.30</td>\n",
       "      <td>아니 천 원이 하자 12,000원에 2,000원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19.30</td>\n",
       "      <td>27.00</td>\n",
       "      <td>아니 천원이 뭐 그 자조 저건 많이 터러 12,000원은 그냥 12,000원에 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>아니 나는 지금 많이 희생했잖아</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>나는 3천은 내 버스비긴 해가지고 내 교통비라서 아쉬워놔 3천원이 그걸 나중에 내...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>41.00</td>\n",
       "      <td>44.00</td>\n",
       "      <td>지금 내라는 게 아니냐 몇 번을 말해?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44.00</td>\n",
       "      <td>49.48</td>\n",
       "      <td>언제? 한 보려면 계속 두 달은 기다려야 되는데</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>49.48</td>\n",
       "      <td>60.00</td>\n",
       "      <td>그건 니가 그냥 일을 안 하는 거네 돈 없다고 찡찡대면서 일단 머리 자르고 돈을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>60.00</td>\n",
       "      <td>62.50</td>\n",
       "      <td>있는 돈부터 계산을 해봐야 될 거 아니야</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>62.50</td>\n",
       "      <td>71.00</td>\n",
       "      <td>남는 돈이 얼마인지 계산 안될 수 있잖아 일단 뭐 뭐가 됐든 이따 말해</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>71.00</td>\n",
       "      <td>73.34</td>\n",
       "      <td>그래, 오뽀가 되겠네</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>73.34</td>\n",
       "      <td>74.84</td>\n",
       "      <td>엇? 엇보는 아니고</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start    end                                               text\n",
       "0    0.00   2.00                                             다시 말해봐\n",
       "1    2.00   5.00                                일단 내가 이천원 먼저 보내줄테니깐\n",
       "2    5.00   9.08                         1만 2천원 나중에 보내줄게 왜 또 줄어 가격이\n",
       "3    9.08  10.54                                      그만 그렇게 말하면 하지\n",
       "4   10.54  11.66                                              너 왔다며\n",
       "5   11.66  14.00                                      아니 그냥 만원 보내주고\n",
       "6   14.00  17.70                                  오천원 나중에 돼 12,000원\n",
       "7   17.70  18.02                                            12,000원\n",
       "8   18.02  18.72                                            12,000원\n",
       "9   18.72  19.30                         아니 천 원이 하자 12,000원에 2,000원\n",
       "10  19.30  27.00   아니 천원이 뭐 그 자조 저건 많이 터러 12,000원은 그냥 12,000원에 3...\n",
       "11  27.00  30.00                                  아니 나는 지금 많이 희생했잖아\n",
       "12  30.00  41.00   나는 3천은 내 버스비긴 해가지고 내 교통비라서 아쉬워놔 3천원이 그걸 나중에 내...\n",
       "13  41.00  44.00                              지금 내라는 게 아니냐 몇 번을 말해?\n",
       "14  44.00  49.48                         언제? 한 보려면 계속 두 달은 기다려야 되는데\n",
       "15  49.48  60.00   그건 니가 그냥 일을 안 하는 거네 돈 없다고 찡찡대면서 일단 머리 자르고 돈을 ...\n",
       "16  60.00  62.50                             있는 돈부터 계산을 해봐야 될 거 아니야\n",
       "17  62.50  71.00            남는 돈이 얼마인지 계산 안될 수 있잖아 일단 뭐 뭐가 됐든 이따 말해\n",
       "18  71.00  73.34                                        그래, 오뽀가 되겠네\n",
       "19  73.34  74.84                                         엇? 엇보는 아니고"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = []\n",
    "for chunk in result[\"chunks\"]:\n",
    "    start = chunk[\"timestamp\"][0]\n",
    "    end = chunk[\"timestamp\"][1]\n",
    "    text = chunk[\"text\"]\n",
    "    df_list.append([start,end,text])\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(df_list,columns=[\"start\",\"end\",\"text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cfc5047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fursew\\project\\open_ai\\.venv\\Lib\\site-packages\\pyannote\\audio\\utils\\reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
      "It can be re-enabled by calling\n",
      "   >>> import torch\n",
      "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
      "   >>> torch.backends.cudnn.allow_tf32 = True\n",
      "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\fursew\\project\\open_ai\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n",
      "c:\\Users\\fursew\\project\\open_ai\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fursew\\project\\open_ai\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fursew\\project\\open_ai\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fursew\\project\\open_ai\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fursew\\project\\open_ai\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fursew\\project\\open_ai\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fursew\\project\\open_ai\\.venv\\Lib\\site-packages\\torchaudio\\_backend\\soundfile_backend.py:71: UserWarning: The MPEG_LAYER_III subtype is unknown to TorchAudio. As a result, the bits_per_sample attribute will be set to 0. If you are seeing this warning, please report by opening an issue on github (after checking for existing/closed ones). You may otherwise ignore this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# instantiate the pipeline\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import torch\n",
    "from pyannote.audio import Pipeline\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"Hugging_API_KEY\")\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "  \"pyannote/speaker-diarization-3.1\",\n",
    "  use_auth_token=token)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    pipeline.to(torch.device(\"cuda:0\"))\n",
    "    print(\"cuda is available\")\n",
    "else:\n",
    "    pipeline.to(torch.device(\"cpu\"))\n",
    "    print(\"cuda is not available\")\n",
    "\n",
    "# run the pipeline on an audio file\n",
    "diarization = pipeline(\"C://Users//fursew//project//open_ai//ch05//음성녹음.mp3\")\n",
    "\n",
    "# dump the diarization output to disk using RTTM format\n",
    "with open(\"audio.rttm\", \"w\",encoding='utf-8') as rttm:\n",
    "    diarization.write_rttm(rttm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
